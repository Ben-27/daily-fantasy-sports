from NN import NN

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader


RANDOM_STATE = 343





dat = pd.read_csv('features_lookback_10.csv')

# feature names
dat.drop(columns=['url_suffix', 'Date'], inplace=True)

# shuffle and split into three sets
train, dev, test = np.split(
    dat.sample(frac=1, random_state=RANDOM_STATE),
    [int(.8*len(dat)), int(.9*len(dat))]
)
print(f'Training set: {train.shape}\n', f'Development set: {dev.shape}\n', f'Testing set: {test.shape}')

X_train, X_dev, X_test = train.iloc[:, 1:], dev.iloc[:, 1:], test.iloc[:, 1:]
y_train, y_dev, y_test = train.iloc[:, 0].to_numpy(), dev.iloc[:, 0].to_numpy(), test.iloc[:, 0].to_numpy()

# center and scale features
x_scaler = StandardScaler()
x_scaler.fit(X_train)
X_train_scaled, X_dev_scaled, X_test_scaled = x_scaler.transform(X_train), x_scaler.transform(X_dev), x_scaler.transform(X_test)

# center and scale targets
y_scaler = StandardScaler()
y_scaler.fit(y_train.reshape(-1,1))
y_train_scaled, y_dev_scaled, y_test_scaled = y_scaler.transform(y_train.reshape(-1,1)), y_scaler.transform(y_dev.reshape(-1,1)), y_scaler.transform(y_test.reshape(-1,1))





dataset = TensorDataset(
    torch.tensor(X_train_scaled).float(), 
    torch.tensor(y_train_scaled.reshape(-1,1)).float()
)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)


dev_dataset = TensorDataset(
    torch.tensor(X_dev_scaled).float(),
    torch.tensor(y_dev_scaled.reshape(-1,1)).float()
)





m_sig = NN(nn.Sequential(
    nn.Linear(dataset[0][0].shape[0], 120),
    nn.Sigmoid(),
    nn.Linear(120, 1),
    nn.Dropout(.5)
))

print(f'Total parameters: {m_sig.get_param_count()}\n')

print(m_sig.model)


m_sig.training_loop(dataloader, devset=dev_dataset, num_epochs=50)

m_sig.plot_losses(x_start=0, ylim=10)

m_sig.calculate_metrics(dev_dataset, y_scaler)





m_deep = NN(nn.Sequential(
    nn.Linear(dataset[0][0].shape[0], 41),
    nn.Sigmoid(),
    nn.Linear(41, 20),
    nn.Sigmoid(),
    nn.Linear(20,10),
    nn.Sigmoid(),
    nn.Linear(10,1),
    nn.Dropout(.5)
))

print(f'Total parameters: {m_deep.get_param_count()}\n')

print(m_deep.model)


m_deep.training_loop(dataloader, devset=dev_dataset, num_epochs=50)

m_deep.plot_losses(x_start=0, ylim=10)

m_deep.calculate_metrics(dev_dataset, y_scaler)





test_dataset = TensorDataset(
    torch.tensor(X_test_scaled).float(),
    torch.tensor(y_test_scaled.reshape(-1,1)).float()
)


m_sig.calculate_metrics(test_dataset, y_scaler)


m_deep.calculate_metrics(test_dataset, y_scaler)



